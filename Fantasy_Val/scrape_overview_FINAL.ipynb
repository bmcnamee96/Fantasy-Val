{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c089568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8f0269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df, team_names):\n",
    "    if df.empty:\n",
    "        return None\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Rename the columns\n",
    "    df_copy.columns = ['name', 'blank', 'rating', 'acs', 'kills', 'deaths', 'assists', 'k/d', 'KAST', 'adr', 'hs', 'fk', 'fd', 'fk/fd']\n",
    "\n",
    "    # Clean the 'name' column\n",
    "    df_copy['name'] = df_copy['name'].str.strip().str.replace('\\t', '').str.replace('\\n', '')\n",
    "    \n",
    "#     # Clean the team names\n",
    "#     for team in team_names:\n",
    "#         df_copy['name'] = df_copy['name'].str.replace(team, '').str.strip()\n",
    "\n",
    "    # Drop all unneeded columns\n",
    "    df_copy = df_copy.drop(columns=['blank', 'rating', 'acs', 'k/d', 'KAST', 'hs', 'fk/fd'])\n",
    "    \n",
    "    # Apply a lambda function to extract the first number from each cell\n",
    "    df_copy['kills'] = df_copy['kills'].apply(lambda x: x.split('\\n')[0] if x else None)\n",
    "\n",
    "    # Use a try-except block to handle potential errors in 'deaths' column processing\n",
    "    try:\n",
    "        df_copy['deaths'] = df_copy['deaths'].apply(lambda x: int(re.findall(r'\\d+', x)[0]) if x else None)\n",
    "    except IndexError:\n",
    "        df_copy['deaths'] = None  # Handle the error by assigning a default value\n",
    "\n",
    "    df_copy['assists'] = df_copy['assists'].apply(lambda x: x.split('\\n')[0] if x else None)\n",
    "    df_copy['adr'] = df_copy['adr'].apply(lambda x: x.split('\\n')[0] if x else None)\n",
    "    df_copy['fk'] = df_copy['fk'].apply(lambda x: x.split('\\n')[0] if x else None)\n",
    "    df_copy['fd'] = df_copy['fd'].apply(lambda x: x.split('\\n')[0] if x else None)\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "def scrape_data(url_list):\n",
    "    all_dfs = {}  # Dictionary to store processed DataFrames for each URL\n",
    "\n",
    "    team_names = ['MIBR', 'LEV', 'SEN', 'NRG', 'FUR', '100T', 'LOUD', 'EG', 'G2', 'C9', 'KRÃœ']\n",
    "\n",
    "    for url in url_list:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = bs(response.content, 'html.parser')\n",
    "\n",
    "            # Initialize lists to store DataFrames for each pass\n",
    "            first_pass_dfs = []\n",
    "            second_pass_dfs = []\n",
    "\n",
    "            # Find all game divs\n",
    "            game_divs = soup.find_all('div', class_='vm-stats-game')\n",
    "\n",
    "            # First pass: Find initial tables\n",
    "            for game_div in game_divs:\n",
    "                table = game_div.find('table', class_='wf-table-inset mod-overview')\n",
    "\n",
    "                if table:\n",
    "                    # Extract table data into a DataFrame\n",
    "                    table_data = []\n",
    "                    rows = table.find_all('tr')\n",
    "                    for row in rows:\n",
    "                        row_data = [cell.text.strip() for cell in row.find_all(['td', 'th'])]\n",
    "                        table_data.append(row_data)\n",
    "\n",
    "                    # Convert table_data into a DataFrame and append to first_pass_dfs list\n",
    "                    df = pd.DataFrame(table_data[1:], columns=table_data[0])  # Assuming first row is header\n",
    "                    first_pass_dfs.append(df)\n",
    "\n",
    "            # Second pass: Find the next tables\n",
    "            for game_div in game_divs:\n",
    "                table = game_div.find('table', class_='wf-table-inset mod-overview')\n",
    "                if table:\n",
    "                    next_table = table.find_next('table', class_='wf-table-inset mod-overview')\n",
    "                    if next_table:\n",
    "                        # Extract table data into a DataFrame\n",
    "                        table_data = []\n",
    "                        rows = next_table.find_all('tr')\n",
    "                        for row in rows:\n",
    "                            row_data = [cell.text.strip() for cell in row.find_all(['td', 'th'])]\n",
    "                            table_data.append(row_data)\n",
    "\n",
    "                        # Convert table_data into a DataFrame and append to second_pass_dfs list\n",
    "                        df = pd.DataFrame(table_data[1:], columns=table_data[0])  # Assuming first row is header\n",
    "                        second_pass_dfs.append(df)\n",
    "\n",
    "            # Process and clean DataFrames from both passes\n",
    "            first_pass_cleaned = [clean_dataframe(df, team_names) for df in first_pass_dfs if not df.empty]\n",
    "            second_pass_cleaned = [clean_dataframe(df, team_names) for df in second_pass_dfs if not df.empty]\n",
    "\n",
    "            # Combine corresponding DataFrames from both passes\n",
    "            combined_dfs = []\n",
    "            min_length = min(len(first_pass_cleaned), len(second_pass_cleaned))\n",
    "            for i in range(min_length):\n",
    "                if first_pass_cleaned[i] is not None and second_pass_cleaned[i] is not None:\n",
    "                    combined_df = pd.concat([first_pass_cleaned[i], second_pass_cleaned[i]], axis=0)\n",
    "                    combined_dfs.append(combined_df)\n",
    "                    combined_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "            all_dfs[url] = combined_dfs\n",
    "\n",
    "        else:\n",
    "            print('Failed to retrieve the webpage. Status code:', response.status_code)\n",
    "\n",
    "    return all_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f02db203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "url_list = [\n",
    " 'https://www.vlr.gg/353177/mibr-vs-leviat-n-champions-tour-2024-americas-stage-2-w1/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353178/sentinels-vs-nrg-esports-champions-tour-2024-americas-stage-2-w1/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353179/furia-vs-100-thieves-champions-tour-2024-americas-stage-2-w1/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353180/loud-vs-evil-geniuses-champions-tour-2024-americas-stage-2-w1/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353181/g2-esports-vs-cloud9-champions-tour-2024-americas-stage-2-w1/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353182/evil-geniuses-vs-furia-champions-tour-2024-americas-stage-2-w2/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353183/sentinels-vs-kr-esports-champions-tour-2024-americas-stage-2-w2/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353184/loud-vs-mibr-champions-tour-2024-americas-stage-2-w2/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353185/leviat-n-vs-100-thieves-champions-tour-2024-americas-stage-2-w2/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353186/nrg-esports-vs-g2-esports-champions-tour-2024-americas-stage-2-w2/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353187/sentinels-vs-cloud9-champions-tour-2024-americas-stage-2-w2/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353188/evil-geniuses-vs-leviat-n-champions-tour-2024-americas-stage-2-w2/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353189/loud-vs-furia-champions-tour-2024-americas-stage-2-w2/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353190/mibr-vs-100-thieves-champions-tour-2024-americas-stage-2-w2/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353191/nrg-esports-vs-kr-esports-champions-tour-2024-americas-stage-2-w2/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353192/g2-esports-vs-kr-esports-champions-tour-2024-americas-stage-2-w3/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353193/loud-vs-leviat-n-champions-tour-2024-americas-stage-2-w3/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353194/mibr-vs-furia-champions-tour-2024-americas-stage-2-w3/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353195/nrg-esports-vs-cloud9-champions-tour-2024-americas-stage-2-w3/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353196/evil-geniuses-vs-100-thieves-champions-tour-2024-americas-stage-2-w3/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353197/cloud9-vs-kr-esports-champions-tour-2024-americas-stage-2-w4/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353198/evil-geniuses-vs-mibr-champions-tour-2024-americas-stage-2-w4/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353199/leviat-n-vs-furia-champions-tour-2024-americas-stage-2-w4/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353200/loud-vs-100-thieves-champions-tour-2024-americas-stage-2-w4/?game=all&tab=overview',\n",
    " 'https://www.vlr.gg/353201/sentinels-vs-g2-esports-champions-tour-2024-americas-stage-2-w4/?game=all&tab=overview'\n",
    "]\n",
    "\n",
    "data_frames = scrape_data(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a17a9819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the second df from each series\n",
    "\n",
    "# Create a list of new keys\n",
    "new_keys = [f'Series {i+1}' for i in range(len(data_frames))]\n",
    "\n",
    "# Create a new dictionary with updated keys\n",
    "re_dfs = dict(zip(new_keys, data_frames.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36488dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[           name kills  deaths assists  adr fk fd\n",
       " 0    zekken SEN    22      14       7  222  7  4\n",
       " 1      Sacy SEN    19      10       9  161  0  2\n",
       " 2   Zellsis SEN    16      10       6  131  1  0\n",
       " 3      TenZ SEN    13      13      14  127  1  1\n",
       " 4    johnqt SEN    10      11       5   96  2  2\n",
       " 5       s0m NRG    14      17       6  142  4  4\n",
       " 6     Ethan NRG    14      15      10  121  3  0\n",
       " 7    Victor NRG    11      17       5  116  2  6\n",
       " 8   FiNESSE NRG     9      16       4   79  1  0\n",
       " 9  crashies NRG    10      16       4   92  0  2,\n",
       "            name kills  deaths assists  adr  fk  fd\n",
       " 0    zekken SEN    46      33      21  213  12   8\n",
       " 1   Zellsis SEN    37      24      22  135   2   1\n",
       " 2      TenZ SEN    36      29      24  134   5   3\n",
       " 3      Sacy SEN    38      26      17  145   3   5\n",
       " 4    johnqt SEN    25      28       9  102   3   4\n",
       " 5       s0m NRG    30      35      21  131   4   6\n",
       " 6     Ethan NRG    32      34      23  118   5   3\n",
       " 7    Victor NRG    34      41      10  150   9  13\n",
       " 8  crashies NRG    23      35      14   92   1   3\n",
       " 9   FiNESSE NRG    21      38       8   90   3   1,\n",
       "            name kills  deaths assists  adr fk fd\n",
       " 0      TenZ SEN    23      16      10  140  4  2\n",
       " 1    zekken SEN    24      19      14  206  5  4\n",
       " 2   Zellsis SEN    21      14      16  138  1  1\n",
       " 3      Sacy SEN    19      16       8  132  3  3\n",
       " 4    johnqt SEN    15      17       4  108  1  2\n",
       " 5     Ethan NRG    18      19      13  117  2  3\n",
       " 6       s0m NRG    16      18      15  123  0  2\n",
       " 7    Victor NRG    23      24       5  177  7  7\n",
       " 8  crashies NRG    13      19      10   92  1  1\n",
       " 9   FiNESSE NRG    12      22       4  100  2  1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_dfs['Series 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "403f82d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dictionary and remove the second item from each list value\n",
    "for key in re_dfs:\n",
    "    if len(re_dfs[key]) > 1:\n",
    "        del re_dfs[key][1]  # Delete the second item (index 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d825abb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[           name kills  deaths assists  adr fk fd\n",
       " 0    zekken SEN    22      14       7  222  7  4\n",
       " 1      Sacy SEN    19      10       9  161  0  2\n",
       " 2   Zellsis SEN    16      10       6  131  1  0\n",
       " 3      TenZ SEN    13      13      14  127  1  1\n",
       " 4    johnqt SEN    10      11       5   96  2  2\n",
       " 5       s0m NRG    14      17       6  142  4  4\n",
       " 6     Ethan NRG    14      15      10  121  3  0\n",
       " 7    Victor NRG    11      17       5  116  2  6\n",
       " 8   FiNESSE NRG     9      16       4   79  1  0\n",
       " 9  crashies NRG    10      16       4   92  0  2,\n",
       "            name kills  deaths assists  adr fk fd\n",
       " 0      TenZ SEN    23      16      10  140  4  2\n",
       " 1    zekken SEN    24      19      14  206  5  4\n",
       " 2   Zellsis SEN    21      14      16  138  1  1\n",
       " 3      Sacy SEN    19      16       8  132  3  3\n",
       " 4    johnqt SEN    15      17       4  108  1  2\n",
       " 5     Ethan NRG    18      19      13  117  2  3\n",
       " 6       s0m NRG    16      18      15  123  0  2\n",
       " 7    Victor NRG    23      24       5  177  7  7\n",
       " 8  crashies NRG    13      19      10   92  1  1\n",
       " 9   FiNESSE NRG    12      22       4  100  2  1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_dfs['Series 2'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4954c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87508fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
