{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c089568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662ce32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names read from file ../Data/name_list.txt\n",
      "Links read from file ../Data/over_list.txt\n"
     ]
    }
   ],
   "source": [
    "# Function to read and print links from the file\n",
    "def read_names(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        names = file.readlines()\n",
    "        names = [name.strip() for name in names]\n",
    "    return names\n",
    "\n",
    "file_path = '../Data/name_list.txt'\n",
    "# Access the links from the file\n",
    "all_names = read_names(file_path)\n",
    "print(f\"Names read from file {file_path}\")\n",
    "\n",
    "# Function to read and print links from the file\n",
    "def read_links(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        links = file.readlines()\n",
    "        links = [link.strip() for link in links]\n",
    "    return links\n",
    "\n",
    "file_path = '../Data/over_list.txt'\n",
    "# Access the links from the file\n",
    "over_list = read_links(file_path)\n",
    "print(f\"Links read from file {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f0269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df, team_names):\n",
    "    if df.empty:\n",
    "        return None\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Rename the columns\n",
    "    df_copy.columns = ['name', 'blank', 'rating', 'acs', 'kills', 'deaths', 'assists', 'k/d', 'KAST', 'adr', 'hs', 'fk', 'fd', 'fk/fd']\n",
    "\n",
    "    # Clean the 'name' column\n",
    "    df_copy['name'] = df_copy['name'].str.strip().str.replace('\\t', '').str.replace('\\n', '')\n",
    "\n",
    "    # Drop all unneeded columns\n",
    "    df_copy = df_copy.drop(columns=['blank', 'rating', 'acs', 'k/d', 'KAST', 'hs', 'fk/fd'])\n",
    "    \n",
    "    # Apply a lambda function to extract the first number from each cell\n",
    "    df_copy['kills'] = df_copy['kills'].apply(lambda x: x.split('\\n')[0] if x else None)\n",
    "\n",
    "    # Use a try-except block to handle potential errors in 'deaths' column processing\n",
    "    try:\n",
    "        df_copy['deaths'] = df_copy['deaths'].apply(lambda x: int(re.findall(r'\\d+', x)[0]) if x else None)\n",
    "    except IndexError:\n",
    "        df_copy['deaths'] = None  # Handle the error by assigning a default value\n",
    "\n",
    "    df_copy['assists'] = df_copy['assists'].apply(lambda x: x.split('\\n')[0] if x else None)\n",
    "    df_copy['adr'] = df_copy['adr'].apply(lambda x: x.split('\\n')[0] if x else None)\n",
    "    df_copy['fk'] = df_copy['fk'].apply(lambda x: x.split('\\n')[0] if x else None)\n",
    "    df_copy['fd'] = df_copy['fd'].apply(lambda x: x.split('\\n')[0] if x else None)\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "def scrape_data(url_list):\n",
    "    all_dfs = {}  # Dictionary to store processed DataFrames for each URL\n",
    "\n",
    "    team_names = ['MIBR', 'LEV', 'SEN', 'NRG', 'FUR', '100T', 'LOUD', 'EG', 'G2', 'C9', 'KRÃœ']\n",
    "\n",
    "    for url in url_list:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = bs(response.content, 'html.parser')\n",
    "\n",
    "            # Initialize lists to store DataFrames for each pass\n",
    "            first_pass_dfs = []\n",
    "            second_pass_dfs = []\n",
    "\n",
    "            # Find all game divs\n",
    "            game_divs = soup.find_all('div', class_='vm-stats-game')\n",
    "\n",
    "            # First pass: Find initial tables\n",
    "            for game_div in game_divs:\n",
    "                table = game_div.find('table', class_='wf-table-inset mod-overview')\n",
    "\n",
    "                if table:\n",
    "                    # Extract table data into a DataFrame\n",
    "                    table_data = []\n",
    "                    rows = table.find_all('tr')\n",
    "                    for row in rows:\n",
    "                        row_data = [cell.text.strip() for cell in row.find_all(['td', 'th'])]\n",
    "                        table_data.append(row_data)\n",
    "\n",
    "                    # Convert table_data into a DataFrame and append to first_pass_dfs list\n",
    "                    df = pd.DataFrame(table_data[1:], columns=table_data[0])  # Assuming first row is header\n",
    "                    first_pass_dfs.append(df)\n",
    "\n",
    "            # Second pass: Find the next tables\n",
    "            for game_div in game_divs:\n",
    "                table = game_div.find('table', class_='wf-table-inset mod-overview')\n",
    "                if table:\n",
    "                    next_table = table.find_next('table', class_='wf-table-inset mod-overview')\n",
    "                    if next_table:\n",
    "                        # Extract table data into a DataFrame\n",
    "                        table_data = []\n",
    "                        rows = next_table.find_all('tr')\n",
    "                        for row in rows:\n",
    "                            row_data = [cell.text.strip() for cell in row.find_all(['td', 'th'])]\n",
    "                            table_data.append(row_data)\n",
    "\n",
    "                        # Convert table_data into a DataFrame and append to second_pass_dfs list\n",
    "                        df = pd.DataFrame(table_data[1:], columns=table_data[0])  # Assuming first row is header\n",
    "                        second_pass_dfs.append(df)\n",
    "\n",
    "            # Process and clean DataFrames from both passes\n",
    "            first_pass_cleaned = [clean_dataframe(df, team_names) for df in first_pass_dfs if not df.empty]\n",
    "            second_pass_cleaned = [clean_dataframe(df, team_names) for df in second_pass_dfs if not df.empty]\n",
    "\n",
    "            # Combine corresponding DataFrames from both passes\n",
    "            combined_dfs = []\n",
    "            min_length = min(len(first_pass_cleaned), len(second_pass_cleaned))\n",
    "            for i in range(min_length):\n",
    "                if first_pass_cleaned[i] is not None and second_pass_cleaned[i] is not None:\n",
    "                    combined_df = pd.concat([first_pass_cleaned[i], second_pass_cleaned[i]], axis=0)\n",
    "                    combined_dfs.append(combined_df)\n",
    "                    combined_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "            all_dfs[url] = combined_dfs\n",
    "\n",
    "        else:\n",
    "            print('Failed to retrieve the webpage. Status code:', response.status_code)\n",
    "\n",
    "    return all_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f02db203",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = scrape_data(over_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a17a9819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the second df from each series\n",
    "\n",
    "# Create a list of new keys\n",
    "new_keys = [f'Series {i+1}' for i in range(len(data_frames))]\n",
    "\n",
    "# Create a new dictionary with updated keys\n",
    "re_dfs = dict(zip(new_keys, data_frames.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36488dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[           name kills  deaths assists  adr fk fd\n",
       " 0    mazin MIBR    20      15      10  161  3  1\n",
       " 1   artzin MIBR    18      15       9  139  7  0\n",
       " 2  ShahZaM MIBR    12      14       9  122  2  1\n",
       " 3   liazzi MIBR    13      14       5  126  0  2\n",
       " 4    Pa1nt MIBR    11      17       6   98  2  4\n",
       " 5       tex LEV    20      15       2  179  3  3\n",
       " 6    Mazino LEV    22      15       9  175  1  3\n",
       " 7     kiNgg LEV    12      14       8  111  2  3\n",
       " 8       C0M LEV    10      14       7  106  0  1\n",
       " 9     aspas LEV    11      16       4  113  2  4,\n",
       "            name kills  deaths assists  adr fk fd\n",
       " 0    mazin MIBR    35      29      15  156  6  2\n",
       " 1   artzin MIBR    34      30      13  144  7  3\n",
       " 2  ShahZaM MIBR    23      29      14  124  3  4\n",
       " 3   liazzi MIBR    21      30       6  104  1  3\n",
       " 4    Pa1nt MIBR    19      35      12  101  4  9\n",
       " 5     kiNgg LEV    34      24      16  158  6  3\n",
       " 6     aspas LEV    32      24       8  144  7  5\n",
       " 7    Mazino LEV    31      29      21  150  2  6\n",
       " 8       C0M LEV    27      27      12  130  2  1\n",
       " 9       tex LEV    29      28       5  143  4  6,\n",
       "            name kills  deaths assists  adr fk fd\n",
       " 0    mazin MIBR    15      14       5  150  3  1\n",
       " 1   artzin MIBR    16      15       4  150  0  3\n",
       " 2  ShahZaM MIBR    11      15       5  127  1  3\n",
       " 3    Pa1nt MIBR     8      18       6  105  2  5\n",
       " 4   liazzi MIBR     8      16       1   80  1  1\n",
       " 5     kiNgg LEV    22      10       8  210  4  0\n",
       " 6     aspas LEV    21       8       4  179  5  1\n",
       " 7       C0M LEV    17      13       5  156  2  0\n",
       " 8    Mazino LEV     9      14      12  124  1  3\n",
       " 9       tex LEV     9      13       3  104  1  3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_dfs['Series 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "403f82d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dictionary and remove the second item from each list value\n",
    "for key in re_dfs:\n",
    "    if len(re_dfs[key]) > 1:\n",
    "        del re_dfs[key][1]  # Delete the second item (index 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d825abb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[           name kills  deaths assists  adr fk fd\n",
       " 0    mazin MIBR    20      15      10  161  3  1\n",
       " 1   artzin MIBR    18      15       9  139  7  0\n",
       " 2  ShahZaM MIBR    12      14       9  122  2  1\n",
       " 3   liazzi MIBR    13      14       5  126  0  2\n",
       " 4    Pa1nt MIBR    11      17       6   98  2  4\n",
       " 5       tex LEV    20      15       2  179  3  3\n",
       " 6    Mazino LEV    22      15       9  175  1  3\n",
       " 7     kiNgg LEV    12      14       8  111  2  3\n",
       " 8       C0M LEV    10      14       7  106  0  1\n",
       " 9     aspas LEV    11      16       4  113  2  4,\n",
       "            name kills  deaths assists  adr fk fd\n",
       " 0    mazin MIBR    15      14       5  150  3  1\n",
       " 1   artzin MIBR    16      15       4  150  0  3\n",
       " 2  ShahZaM MIBR    11      15       5  127  1  3\n",
       " 3    Pa1nt MIBR     8      18       6  105  2  5\n",
       " 4   liazzi MIBR     8      16       1   80  1  1\n",
       " 5     kiNgg LEV    22      10       8  210  4  0\n",
       " 6     aspas LEV    21       8       4  179  5  1\n",
       " 7       C0M LEV    17      13       5  156  2  0\n",
       " 8    Mazino LEV     9      14      12  124  1  3\n",
       " 9       tex LEV     9      13       3  104  1  3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_dfs['Series 1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f3326f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary keys to list\n",
    "values_list = list(re_dfs.values())\n",
    "\n",
    "# Flatten the list of lists into a single list of lists\n",
    "flattened_list = [item for sublist in values_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99cc1622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a game_id counter\n",
    "game_id = 0\n",
    "\n",
    "# Add game_id column to each DataFrame in the list\n",
    "for df in flattened_list:\n",
    "    df['game_id'] = game_id\n",
    "    game_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edfa8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all DataFrames in the list\n",
    "concatenated_df = pd.concat(flattened_list, ignore_index=True)\n",
    "\n",
    "# Extract team_abrev from name column\n",
    "concatenated_df['team_abrev'] = concatenated_df['name'].apply(lambda x: x.split()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72a7d23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>kills</th>\n",
       "      <th>deaths</th>\n",
       "      <th>assists</th>\n",
       "      <th>adr</th>\n",
       "      <th>fk</th>\n",
       "      <th>fd</th>\n",
       "      <th>game_id</th>\n",
       "      <th>team_abrev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mazin MIBR</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MIBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artzin MIBR</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>139</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MIBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ShahZaM MIBR</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MIBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>liazzi MIBR</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>MIBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pa1nt MIBR</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>MIBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>trent G2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>62</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>valyn G2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>62</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>JonahP G2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>62</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>leaf G2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>62</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>icy G2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>62</td>\n",
       "      <td>G2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name kills deaths assists   adr    fk    fd  game_id team_abrev\n",
       "0      mazin MIBR    20     15      10   161     3     1        0       MIBR\n",
       "1     artzin MIBR    18     15       9   139     7     0        0       MIBR\n",
       "2    ShahZaM MIBR    12     14       9   122     2     1        0       MIBR\n",
       "3     liazzi MIBR    13     14       5   126     0     2        0       MIBR\n",
       "4      Pa1nt MIBR    11     17       6    98     2     4        0       MIBR\n",
       "..            ...   ...    ...     ...   ...   ...   ...      ...        ...\n",
       "625      trent G2  None   None    None  None  None  None       62         G2\n",
       "626      valyn G2  None   None    None  None  None  None       62         G2\n",
       "627     JonahP G2  None   None    None  None  None  None       62         G2\n",
       "628       leaf G2  None   None    None  None  None  None       62         G2\n",
       "629        icy G2  None   None    None  None  None  None       62         G2\n",
       "\n",
       "[630 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5033d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_names = concatenated_df['name'].unique()\n",
    "stat_names_sorted = sorted(stat_names, key=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25755cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_data = {'name': ['Apoth EG', 'artzin MIBR', 'aspas LEV', 'Asuna 100T', 'bang 100T', 'Boostio 100T', 'C0M LEV', \n",
    "                         'cauanzin LOUD', 'crashies NRG', 'Cryocells 100T', 'Derrek EG', 'eeiu 100T', 'Ethan NRG', \n",
    "                         'FiNESSE NRG', 'havoc FUR', 'heat KRÃœ', 'icy G2', 'jawgemo EG', 'johnqt SEN', 'JonahP G2', \n",
    "                         'keznit KRÃœ', 'Khalil FUR', 'kiNgg LEV', 'Klaus KRÃœ', 'leaf G2', 'Less LOUD', 'liazzi MIBR', \n",
    "                         'mazin MIBR', 'Mazino LEV', 'Melser KRÃœ', 'moose C9', 'mta KRÃœ', 'mwzera FUR', 'NaturE EG', \n",
    "                         'nzr FUR', 'OXY C9', 'Pa1nt MIBR', 'Palla MIBR', 'pANcada LOUD', 'rich MIBR', 'runi C9', 's0m NRG', \n",
    "                         'saadhak LOUD', 'Sacy SEN', 'ShahZaM MIBR', 'Shyy KRÃœ', 'supamen EG', 'TenZ SEN', 'tex LEV', \n",
    "                         'trent G2', 'tuyz LOUD', 'valyn G2', 'vanity C9', 'Victor NRG', 'xand FUR', 'Xeppaa C9', \n",
    "                         'zekken SEN', 'Zellsis SEN'],\n",
    "                'player_name': ['Apoth', 'artzin', 'aspas', 'Asuna', 'bang', 'Boostio', 'C0M', 'cauanzin', 'crashies', \n",
    "                               'Cryocells', 'Derrek', 'eeiu', 'Ethan', 'FiNESSE', 'havoc', 'heat', 'icy', 'jawgemo', 'johnqt', \n",
    "                               'JonahP', 'keznit', 'Khalil', 'kiNgg', 'Klaus', 'leaf', 'Less', 'liazzi', 'mazin', 'Mazino', \n",
    "                               'Melser', 'moose', 'mta', 'mwzera', 'NaturE', 'nzr', 'OXY', 'Pa1nt', 'Palla', 'pANcada', 'rich', \n",
    "                               'runi', 's0m', 'saadhak', 'Sacy', 'ShahZaM', 'Shyy', 'supamen', 'TenZ', 'tex', 'trent', 'tuyz', \n",
    "                               'valyn', 'vanity', 'Victor', 'xand', 'Xeppaa', 'zekken', 'Zellsis']}\n",
    "\n",
    "replace_df = pd.DataFrame(replace_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f42e878b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'kills', 'deaths', 'assists', 'adr', 'fk', 'fd', 'game_id',\n",
       "       'team_abrev'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace names in df using replace_df\n",
    "for index, row in replace_df.iterrows():\n",
    "    concatenated_df['name'] = concatenated_df['name'].replace(row['name'], row['player_name'])\n",
    "\n",
    "concatenated_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b01fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = ['player_name', 'kills', 'deaths', 'assists', 'adr', 'fk', 'fd', 'game_id', 'team_abrev']\n",
    "concatenated_df.columns = new_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa0cdd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = ['game_id', 'player_name', 'team_abrev', 'kills', 'deaths', 'assists', 'adr', 'fk', 'fd']\n",
    "\n",
    "concatenated_df = concatenated_df[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17c09181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>player_name</th>\n",
       "      <th>team_abrev</th>\n",
       "      <th>kills</th>\n",
       "      <th>deaths</th>\n",
       "      <th>assists</th>\n",
       "      <th>adr</th>\n",
       "      <th>fk</th>\n",
       "      <th>fd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>62</td>\n",
       "      <td>TenZ</td>\n",
       "      <td>SEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>62</td>\n",
       "      <td>zekken</td>\n",
       "      <td>SEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>62</td>\n",
       "      <td>Sacy</td>\n",
       "      <td>SEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>62</td>\n",
       "      <td>johnqt</td>\n",
       "      <td>SEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>62</td>\n",
       "      <td>Zellsis</td>\n",
       "      <td>SEN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>62</td>\n",
       "      <td>trent</td>\n",
       "      <td>G2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>62</td>\n",
       "      <td>valyn</td>\n",
       "      <td>G2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>62</td>\n",
       "      <td>JonahP</td>\n",
       "      <td>G2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>62</td>\n",
       "      <td>leaf</td>\n",
       "      <td>G2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>62</td>\n",
       "      <td>icy</td>\n",
       "      <td>G2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     game_id player_name team_abrev kills deaths assists   adr    fk    fd\n",
       "620       62        TenZ        SEN  None   None    None  None  None  None\n",
       "621       62      zekken        SEN  None   None    None  None  None  None\n",
       "622       62        Sacy        SEN  None   None    None  None  None  None\n",
       "623       62      johnqt        SEN  None   None    None  None  None  None\n",
       "624       62     Zellsis        SEN  None   None    None  None  None  None\n",
       "625       62       trent         G2  None   None    None  None  None  None\n",
       "626       62       valyn         G2  None   None    None  None  None  None\n",
       "627       62      JonahP         G2  None   None    None  None  None  None\n",
       "628       62        leaf         G2  None   None    None  None  None  None\n",
       "629       62         icy         G2  None   None    None  None  None  None"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b79802c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV file\n",
    "concatenated_df.to_csv('../Data/over_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19a9485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
